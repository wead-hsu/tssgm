import argparse

def init_arguments(parser):
    # MODEL
    parser.add_argument('--model_path', type=str, default='sssp.models.semiclf.semiclf_sample_aaai17', help='model_path')
    parser.add_argument('--model_name', type=str, default='SemiClassifier', help='model_name')
    parser.add_argument('--classifier_type', type=str, default='LSTM', help='Type of RNN')
    parser.add_argument('--rnn_type', type=str, default='LSTM', help='Type of RNN')
    parser.add_argument('--num_units', type=int, default=512, help='Dimension of hidden state of RNN')
    parser.add_argument('--batch_size_label', type=int, default=20, help='batch_size')
    parser.add_argument('--batch_size_unlabel', type=int, default=20, help='batch_size')
    parser.add_argument('--use_sampled_softmax', default=False, help='If use sampled_softmax to speed up')
    parser.add_argument('--num_samples', type=int, default=512, help='Number of samples used in sampled_softmax')
    parser.add_argument('--num_layers', type=int, default=1, help='num_layers')
    parser.add_argument('--dim_z', type=int, default=100, help='Dimension of latent code')
    parser.add_argument('--alpha', type=float, default=1.0, help='rescale for unlabeled clf')
    parser.add_argument('--num_pretrain_steps', type=int, default=8000, help='Number of step for pretraining')
    parser.add_argument('--use_weights', action='store_true', default=False, help='if use, multiply weights in decoder')
    parser.add_argument('--use_binaryweights', action='store_true', default=False, help='if use, attention weights will be binarized.')
    parser.add_argument('--keep_rate', type=float, default=0.5, help='keep rate')
    parser.add_argument('--word_keep_rate', type=float, default=0.9, help='keep rate')
    parser.add_argument('--decoder_type', type=str, default='lstm', help='[lstm, sclstm]')
    parser.add_argument('--sample_unlabel', type=str, default='False', help='[S1, S2, False]')

    # TRAINING
    parser.add_argument('--max_epoch', type=int, default=400, help='Maximum number of epochs')
    parser.add_argument('--grad_clip', type=float, default=10.0, help='grad_clip')
    parser.add_argument('--max_norm', type=float, default=20.0, help='max_norm')
    parser.add_argument('--train_embd', type=bool, default=True, help='If train embedding')
    parser.add_argument('--learning_rate', type=float, default=0.0004, help='Learning rate')
    parser.add_argument('--show_every', type=int, default=100, help='Number of batch between showing the results')
    parser.add_argument('--save_every', type=int, default=2000, help='Number of batch between saving the results')
    parser.add_argument('--validate_every', type=int, default=1000, help='Number of batch between validating the results')
    parser.add_argument('--decay_rate', type=float, default=0.99, help='decay_rate')
    parser.add_argument('--decay_steps', type=float, default=100, help='decay_steps')
   
    # ENVORIMENTS
    parser.add_argument('--max_to_keep', type=int, default=0, help='max_to_keep')
    parser.add_argument('--log_prefix', type=str, default='semiclf', help='Log prefix')

    # DATASET
    dataset = 'agnews' #['beer', 'case', 'agnews']
    if dataset == 'case':
        parser.add_argument('--train_label_path', type=str, default='data/case_type_clf/proc/labeled.data.idx', help='Directory of datasets')
        parser.add_argument('--train_unlabel_path', type=str, default='data/case_type_clf/proc/unlabeled.data.idx', help='Directory of datasets')
        parser.add_argument('--valid_path', type=str, default='data/case_type_clf/proc/dev.data.idx', help='Directory of datasets')
        parser.add_argument('--test_path', type=str, default='data/case_type_clf/proc/test.data.idx', help='Directory of datasets')
        parser.add_argument('--vocab_path', type=str, default='data/case_type_clf/proc/vocab.pkl', help='vocab_path')
        parser.add_argument('--save_dir', type=str, default='results/tmp1', help='Directory for saving')
        parser.add_argument('--klw_w', type=float, default=3e-5, help='klw = klw_w * step + klw_b')
        parser.add_argument('--klw_b', type=float, default=3e5, help='klw = klw_w * step + klw_b')
        #parser.add_argument('--init_from', type=str, default='results/semiclf-gatedctxgru2-constweight-all/semiclf-20000', help='Restore from the trained model path')
        parser.add_argument('--init_from', type=str, default=None, help='Restore from the trained model path')
        parser.add_argument('--num_classes', type=int, default=12, help='Number of classes')
        parser.add_argument('--vocab_size', type=int, default=20000, help='Size of vocabulary')
        parser.add_argument('--max_sent_len', type=int, default=100, help='maximum sentence length')
    elif dataset == 'beer':
        parser.add_argument('--train_label_path', type=str, default='data/beer/proc/cls_0-aspect_1-clf/train_all.data.idx', help='Directory of datasets')
        parser.add_argument('--train_unlabel_path', type=str, default='data/beer/proc/cls_0-aspect_1-clf/unlabeled.data.idx', help='Directory of datasets')
        parser.add_argument('--valid_path', type=str, default='data/beer/proc/cls_0-aspect_1-clf/dev.data.idx', help='Directory of datasets')
        parser.add_argument('--test_path', type=str, default='data/beer/proc/cls_0-aspect_1-clf/test.data.idx', help='Directory of datasets')
        parser.add_argument('--vocab_path', type=str, default='data/beer/proc/cls_0-aspect_1-clf/proc/vocab.pkl', help='vocab_path')
        parser.add_argument('--save_dir', type=str, default='results/tmp', help='Directory for saving')
        parser.add_argument('--klw_w', type=float, default=3e-5, help='klw = klw_w * step + klw_b')
        parser.add_argument('--klw_b', type=float, default=3e5, help='klw = klw_w * step + klw_b')
        #parser.add_argument('--init_from', type=str, default='results/semiclf/semiclf-8000', help='Restore from the trained model path')
        parser.add_argument('--init_from', type=str, default=None, help='Restore from the trained model path')
        parser.add_argument('--num_classes', type=int, default=2, help='Number of classes')
        parser.add_argument('--vocab_size', type=int, default=20000, help='Size of vocabulary')
    elif dataset == 'agnews':
        #parser.add_argument('--train_label_path', type=str, default='data/ag_news/proc/labeled.data.idx', help='Directory of datasets')
        #parser.add_argument('--train_unlabel_path', type=str, default='data/ag_news/proc/unlabeled.data.idx', help='Directory of datasets')
        #parser.add_argument('--valid_path', type=str, default='data/ag_news/proc/valid.data.idx', help='Directory of datasets')
        #parser.add_argument('--test_path', type=str, default='data/ag_news/proc/test.data.idx', help='Directory of datasets')
        #parser.add_argument('--vocab_path', type=str, default='data/ag_news/proc/vocab.pkl', help='vocab_path')
        
        parser.add_argument('--train_label_path', type=str, default='data/ag_news/ag8000/labeled.data.idx', help='Directory of datasets')
        parser.add_argument('--train_unlabel_path', type=str, default='data/ag_news/ag8000/unlabeled.data.idx', help='Directory of datasets')
        parser.add_argument('--valid_path', type=str, default='data/ag_news/ag8000/valid.data.idx', help='Directory of datasets')
        parser.add_argument('--test_path', type=str, default='data/ag_news/ag8000/test.data.idx', help='Directory of datasets')
        parser.add_argument('--vocab_path', type=str, default='data/ag_news/ag8000/vocab.pkl', help='vocab_path')
        
        parser.add_argument('--save_dir', type=str, default='results/semiclf-agnews-gru-hard-changenorm-softmax-dropoutfc', help='Directory for saving')
        parser.add_argument('--klw_w', type=float, default=3e-5, help='klw = klw_w * step + klw_b')
        parser.add_argument('--klw_b', type=float, default=3e5, help='klw = klw_w * step + klw_b')
        #parser.add_argument('--init_from', type=str, default='results/semiclf-gatedctxgru2-constweight-all/semiclf-20000', help='Restore from the trained model path')
        parser.add_argument('--init_from', type=str, default=None, help='Restore from the trained model path')
        parser.add_argument('--num_classes', type=int, default=4, help='Number of classes')
        parser.add_argument('--vocab_size', type=int, default=23829, help='Size of vocabulary')
        parser.add_argument('--max_sent_len', type=int, default=100, help='maximum sentence length')
        parser.add_argument('--embd_path', type=str, default='data/ag_news/ag8000/embd.pkl', help='embd_path')
        #parser.add_argument('--embd_path', type=str, default=None, help='embd_path')
        parser.add_argument('--embd_dim', type=int, default=300, help='Dimension of embedding matrix')

    #for debug
    parser.add_argument('--fixirrelevant', action='store_true', default=False, help='If fix the NAN logit')
    parser.add_argument('--w_regl1', type=float, default=0.0, help='coefficient for l1 regulariztion')
    parser.add_argument('--w_regdiff', type=float, default=0.0, help='coefficient for l1 diff regulariztion')
    parser.add_argument('--w_regsharp', type=float, default=0.0, help='coefficient for l1 diff regulariztion')
    parser.add_argument('--w_regfrobenius', type=float, default=0.0, help='coefficient for l1 diff regulariztion')
    parser.add_argument('--fix_sent_len', type=int, default=-1, help='if use cnn, sent length should be fixed')
    parser.add_argument('--filter_size', type=int, default=3, help='filter size for cnn')
    parser.add_argument('--num_filters', type=int, default=30, help='number of filters for cnn')

